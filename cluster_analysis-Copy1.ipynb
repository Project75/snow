{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "#import mpld3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98223,)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('../dump_cat2.csv')\n",
    "X2=df.Short_description\n",
    "Y2=df.Category\n",
    "print(X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "End User Services    24857\n",
       "Application          23610\n",
       "Security             19735\n",
       "Server                9595\n",
       "Network               7042\n",
       "HelpDesk              6724\n",
       "EAI Interface         2199\n",
       "Telecom               2141\n",
       "Human Resources        948\n",
       "Storage                775\n",
       "EAI Component          597\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24857,) (23610,)\n"
     ]
    }
   ],
   "source": [
    "X1 =df[df.Category=='End User Services'].Short_description\n",
    "X2 =df[df.Category=='Application'].Short_description\n",
    "X3 =df[df.Category=='Security'].Short_description\n",
    "print(X1.shape,X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14     network---customer wanted his acc to be unlock...\n",
       "20         Network account- locked || user id- djames003\n",
       "101                                  Phishing simulation\n",
       "110    network---customer wanted network password res...\n",
       "184    Network account - login issue || user id- dmon...\n",
       "Name: Short_description, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "lemmer=WordNetLemmatizer()\n",
    "\n",
    "def pre_process(X):\n",
    "    pat = r'[^A-Za-z ]+'\n",
    "    X = X.str.replace(pat, ' ',regex=True)\n",
    "    X = X.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    X = X.apply(lambda x: ' '.join([lemmer.lemmatize(word) for word in x.split()]))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27     WOW / Workstation on Wheels || WOW / Workstati...\n",
      "93     Keyboard---  Few keys not working || Device id...\n",
      "141                                Wow:Unable to turn on\n",
      "256        Workstation - Needs monitiors to be added || \n",
      "260                     Clairvia - Not able to login || \n",
      "Name: Short_description, dtype: object\n",
      "11     FW microviewer displaying antibiotic properly ...\n",
      "52     MS phxasp unable login user id kquinteros TT a...\n",
      "58     clairvia able login user id sgreen Loc Bakersf...\n",
      "114        nmscust fw data mdf main mdm b Network Outage\n",
      "115          nmscust fw data mdf main mdm Network Outage\n",
      "Name: Short_description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#X1 = pre_process(X1)\n",
    "X2 = pre_process(X2)\n",
    "print(X1[:5])\n",
    "print(X2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load nltk's English stopwords as variable called 'stopwords'\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.91 s\n",
      "(23610, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer( max_features=5000,\n",
    "                                  stop_words='english',\n",
    "                                  use_idf=True, tokenizer=tokenize_only, ngram_range=(1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(X2.values.astype('U'))\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 10\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "%time km.fit(tfidf_matrix)\n",
    "clusters = km.labels_.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: error, getting, communication, unable, getting error, error message, message, id, error communication, login error, gecb, ms, exception, dev, unable login error, ms error, device, dev id, login, error dev,\n",
      "Cluster 1: unable login, login, unable, login username, unable login username, username, ms unable login, ms unable, ms, phxasp, id, axway, unable login dev, ess unable login, ess unable, login dev, ess, login dev id, unable login userid, login userid,\n",
      "Cluster 2: reset, password, password reset, hduv, reset user, password reset user, user, need password, need password reset, login, need, reset password, reset user id, user id, issue, id, hduv reset, hduv password, resolved, hduv password reset,\n",
      "Cluster 3: account, locked, account locked, ii, locked user, user, ms, account locked user, user id, ms account, unlocked, id, locked user id, resolved, login account, login account locked, issue resolved, issue, ms account locked, unlocked account,\n",
      "Cluster 4: cerner, powerchart, cerner powerchart, patient, powerchart unable, unable, issue, firstnet, cerner firstnet, crossing, order, cerner powerchart unable, careb, missing, id, list, user, showing, cerner surginet, powerchart patient,\n",
      "Cluster 5: unable, id, issue, access, user, able, dev, ms, need, dev id, patient, login, device, print, phxasp, launch, application, lawson, journey, loc,\n",
      "Cluster 6: login user, login user id, unable login user, user id, login, user, id, unable login, unable, able login, able login user, able, m, hduv, ms unable login, ms, phxasp, ms unable, phxasp unable login, account,\n",
      "Cluster 7: process, phx, chw edu, edu, chw, edu process, chw edu process, running, service, edu process service, called, process service called, process service, service called, vapp chw, vapp chw edu, vapp, phx vapp, phx vapp chw, phx app,\n",
      "Cluster 8: monitor http, url monitor, url monitor http, http, url, monitor, status, org, dignityhealth, dignityhealth org, monitor http www, www, http www, org status, apps dignityhealth, apps dignityhealth org, http apps dignityhealth, http apps, apps, monitor http apps,\n",
      "Cluster 9: job, ms, ms job, completed exit status, active job completed, job completed exit, job completed, completed exit, exit status, active job, exit, completed, active, phxasp job, phxasp, status, unlocked, lock, job locked, ms phxasp job,\n"
     ]
    }
   ],
   "source": [
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "    \n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    #terms_map['index'] = i\n",
    "    list = [] \n",
    "    for ind in order_centroids[i, :20]:\n",
    "        print(' %s' % terms[ind], end=',')\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0: date, notification text, text, notification, amcore date, amcore, text amcore, notification text amcore, text amcore date, ticket new event, secureworks ticket, secureworks, disruption, disruption security, new event, disruption security ct, security ct, flow disruption security, flow disruption, flow,\n",
      "Cluster 1: network unable login, network unable, unable login username, login username, unable login, unable, login, username, network, acc, unlocked acc, unlocked, unable login network, unable login user, hduv, login network, login user, hduv password, hduv password reset, id,\n",
      "Cluster 2: account locked, locked, account, account locked user, locked user, network account locked, locked user id, network account, network, unlocked, user, unable login account, unlocked account, login account locked, user id, login account, id, account locked username, locked username, account account locked,\n",
      "Cluster 3: login, user, unable, id, account, network, unable login, password, user id, access, issue, login user, login user id, unable login user, duo, resolved, able, issue resolved, reset, hduv,\n",
      "Cluster 4: reset, password reset, password, password reset user, reset user, network password, network password reset, need password reset, need password, network, need, reset user id, password reset username, reset username, user, login need password, login need, unable login need, account password reset, network account,\n",
      "Cluster 5: ii, ii user, ii user id, ii issue, ii issue resolved, network ii, ii needs, issue resolved, resolved, ii needs password, reset ii, ii account, password reset ii, ii account locked, locked ii, network ii account, account locked ii, locked ii user, reset ii user, network ii needs,\n",
      "Cluster 6: customer unable, customer unable login, account customer unable, unable login user, network account customer, account customer, customer, login user, login user id, unable login, unable, user id, id, login, account, user, network account, network, account unable login, account unable,\n",
      "Cluster 7: network able login, network able, able login, able, userid, able login user, login, able login account, account locked userid, locked userid, able login needs, login needs, login needs password, password reset userid, reset userid, network, login account locked, login account, needs password reset, needs password,\n",
      "Cluster 8: issue, network account issue, account issue, issue user, account issue unable, issue unable, issue user id, issue unable login, user id, id, network account, user, login issue, login, account, network, login issue user, account issue user, issue resolved, resolved,\n",
      "Cluster 9: account lock, lock, network account lock, account, network account, account lock user, lock user, account account lock, network, account lock unable, lock unable, lock unable login, network account account, account account, lock able login, lock able, account lock able, login, user, able login,\n"
     ]
    }
   ],
   "source": [
    "true_k = num_clusters\n",
    "terms_map = pd.DataFrame(index=np.arange(0, true_k),columns=['terms'])\n",
    "#terms_map['data_index'] = X3.index.values\n",
    "#terms_map['cluster'] = km.labels_\n",
    "\n",
    "if not opts.use_hashing:\n",
    "    print(\"Top terms per cluster:\")\n",
    "\n",
    "    if opts.n_components:\n",
    "        original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "        order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "    else:\n",
    "        order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "    terms = tfidf_vectorizer.get_feature_names()\n",
    "    \n",
    "    for i in range(true_k):\n",
    "        print(\"Cluster %d:\" % i, end='')\n",
    "        #terms_map['index'] = i\n",
    "        list = [] \n",
    "        for ind in order_centroids[i, :20]:\n",
    "            print(' %s' % terms[ind], end=',')\n",
    "        \n",
    "        for ind in order_centroids[i, :100]:\n",
    "            list.append(terms[ind])\n",
    "        str = ', '.join(list) \n",
    "        terms_map.iloc[i] = str\n",
    "        print()\n",
    "#print(terms_map.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Security - Top terms"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Top terms per cluster:\n",
    "Cluster 0: date, notification text, text, notification, amcore date, amcore, text amcore, notification text amcore, text amcore date, ticket new event, secureworks ticket, secureworks, disruption, disruption security, new event, disruption security ct, security ct, flow disruption security, flow disruption, flow,\n",
    "\n",
    "Cluster 1: network unable login, network unable, unable login username, login username, unable login, unable, login, username, network, acc, unlocked acc, unlocked, unable login network, unable login user, hduv, login network, login user, hduv password, hduv password reset, id,\n",
    "\n",
    "Cluster 2: account locked, locked, account, account locked user, locked user, network account locked, locked user id, network account, network, unlocked, user, unable login account, unlocked account, login account locked, user id, login account, id, account locked username, locked username, account account locked,\n",
    "\n",
    "Cluster 3: login, user, unable, id, account, network, unable login, password, user id, access, issue, login user, login user id, unable login user, duo, resolved, able, issue resolved, reset, hduv,\n",
    "\n",
    "Cluster 4: reset, password reset, password, password reset user, reset user, network password, network password reset, need password reset, need password, network, need, reset user id, password reset username, reset username, user, login need password, login need, unable login need, account password reset, network account,\n",
    "\n",
    "Cluster 5: ii, ii user, ii user id, ii issue, ii issue resolved, network ii, ii needs, issue resolved, resolved, ii needs password, reset ii, ii account, password reset ii, ii account locked, locked ii, network ii account, account locked ii, locked ii user, reset ii user, network ii needs,\n",
    "\n",
    "Cluster 6: customer unable, customer unable login, account customer unable, unable login user, network account customer, account customer, customer, login user, login user id, unable login, unable, user id, id, login, account, user, network account, network, account unable login, account unable,\n",
    "\n",
    "Cluster 7: network able login, network able, able login, able, userid, able login user, login, able login account, account locked userid, locked userid, able login needs, login needs, login needs password, password reset userid, reset userid, network, login account locked, login account, needs password reset, needs password,\n",
    "Cluster 8: issue, network account issue, account issue, issue user, account issue unable, issue unable, issue user id, issue unable login, user id, id, network account, user, login issue, login, account, network, login issue user, account issue user, issue resolved, resolved,\n",
    "Cluster 9: account lock, lock, network account lock, account, network account, account lock user, lock user, account account lock, network, account lock unable, lock unable, lock unable login, network account account, account account, lock able login, lock able, account lock able, login, user, able login,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all terms in cluster index\n",
    "#print(terms_map.terms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = X4.index.values\n",
    "cluster_map['cluster'] = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44    3422\n",
       "1      999\n",
       "20     976\n",
       "9      686\n",
       "14     685\n",
       "36     641\n",
       "13     619\n",
       "12     612\n",
       "11     585\n",
       "41     549\n",
       "8      508\n",
       "49     497\n",
       "10     478\n",
       "15     454\n",
       "2      425\n",
       "3      389\n",
       "19     377\n",
       "46     376\n",
       "4      352\n",
       "7      330\n",
       "28     300\n",
       "43     298\n",
       "34     291\n",
       "17     256\n",
       "32     251\n",
       "21     245\n",
       "35     244\n",
       "40     241\n",
       "6      221\n",
       "5      220\n",
       "26     216\n",
       "25     214\n",
       "30     214\n",
       "42     207\n",
       "16     202\n",
       "22     201\n",
       "23     193\n",
       "37     192\n",
       "48     180\n",
       "45     175\n",
       "27     161\n",
       "31     145\n",
       "47     143\n",
       "0      135\n",
       "24     128\n",
       "38     124\n",
       "39     109\n",
       "18      96\n",
       "33      91\n",
       "29      82\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_map['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Usage: ipykernel_launcher.py [options]\n",
      "\n",
      "Options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --lsa=N_COMPONENTS    Preprocess documents with latent semantic analysis.\n",
      "  --no-minibatch        Use ordinary k-means algorithm (in batch mode).\n",
      "  --no-idf              Disable Inverse Document Frequency feature weighting.\n",
      "  --use-hashing         Use a hashing feature vectorizer\n",
      "  --n-features=N_FEATURES\n",
      "                        Maximum number of features (dimensions) to extract\n",
      "                        from text.\n",
      "  --verbose             Print progress reports inside k-means algorithm.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# Display progress logs on stdout\n",
    "#logging.basicConfig(level=logging.INFO,\n",
    "#                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "# parse commandline arguments\n",
    "op = OptionParser()\n",
    "op.add_option(\"--lsa\",\n",
    "              dest=\"n_components\", type=\"int\",\n",
    "              help=\"Preprocess documents with latent semantic analysis.\")\n",
    "op.add_option(\"--no-minibatch\",\n",
    "              action=\"store_false\", dest=\"minibatch\", default=True,\n",
    "              help=\"Use ordinary k-means algorithm (in batch mode).\")\n",
    "op.add_option(\"--no-idf\",\n",
    "              action=\"store_false\", dest=\"use_idf\", default=True,\n",
    "              help=\"Disable Inverse Document Frequency feature weighting.\")\n",
    "op.add_option(\"--use-hashing\",\n",
    "              action=\"store_true\", default=False,\n",
    "              help=\"Use a hashing feature vectorizer\")\n",
    "op.add_option(\"--n-features\", type=int, default=10000,\n",
    "              help=\"Maximum number of features (dimensions)\"\n",
    "                   \" to extract from text.\")\n",
    "op.add_option(\"--verbose\",\n",
    "              action=\"store_true\", dest=\"verbose\", default=False,\n",
    "              help=\"Print progress reports inside k-means algorithm.\")\n",
    "\n",
    "print(__doc__)\n",
    "op.print_help()\n",
    "\n",
    "\n",
    "def is_interactive():\n",
    "    return not hasattr(sys.modules['__main__'], '__file__')\n",
    "\n",
    "# work-around for Jupyter notebook and IPython console\n",
    "argv = [] if is_interactive() else sys.argv[1:]\n",
    "(opts, args) = op.parse_args(argv)\n",
    "if len(args) > 0:\n",
    "    op.error(\"this script takes no arguments.\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#strip any proper nouns (NNP) or plural proper nouns (NNPS) from a text\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "def strip_proppers_POS(text):\n",
    "    tagged = pos_tag(text.split()) #use NLTK's part of speech tagger\n",
    "    non_propernouns = [word for word,pos in tagged if pos != 'NNP' and pos != 'NNPS']\n",
    "    return non_propernouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical document clustering -wip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "-59",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-a4940d4a9f16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# set size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdendrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinkage_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"right\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m plt.tick_params(    axis= 'x',          # changes apply to the x-axis\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36mdendrogram\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color)\u001b[0m\n\u001b[0;32m   2363\u001b[0m         \u001b[0mcontraction_marks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontraction_marks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2364\u001b[0m         \u001b[0mlink_color_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink_color_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2365\u001b[1;33m         above_threshold_color=above_threshold_color)\n\u001b[0m\u001b[0;32m   2366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_plot\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_dendrogram_calculate_info\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, i, iv, ivl, n, icoord_list, dcoord_list, lvs, mhr, current_color, color_list, currently_below_threshold, leaf_label_func, level, contraction_marks, link_color_func, above_threshold_color)\u001b[0m\n\u001b[0;32m   2616\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_marks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontraction_marks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2617\u001b[0m             \u001b[0mlink_color_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink_color_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2618\u001b[1;33m             above_threshold_color=above_threshold_color)\n\u001b[0m\u001b[0;32m   2619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2620\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_dendrogram_calculate_info\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, i, iv, ivl, n, icoord_list, dcoord_list, lvs, mhr, current_color, color_list, currently_below_threshold, leaf_label_func, level, contraction_marks, link_color_func, above_threshold_color)\u001b[0m\n\u001b[0;32m   2616\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_marks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontraction_marks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2617\u001b[0m             \u001b[0mlink_color_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink_color_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2618\u001b[1;33m             above_threshold_color=above_threshold_color)\n\u001b[0m\u001b[0;32m   2619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2620\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_dendrogram_calculate_info\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, i, iv, ivl, n, icoord_list, dcoord_list, lvs, mhr, current_color, color_list, currently_below_threshold, leaf_label_func, level, contraction_marks, link_color_func, above_threshold_color)\u001b[0m\n\u001b[0;32m   2616\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_marks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontraction_marks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2617\u001b[0m             \u001b[0mlink_color_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink_color_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2618\u001b[1;33m             above_threshold_color=above_threshold_color)\n\u001b[0m\u001b[0;32m   2619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2620\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_dendrogram_calculate_info\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, i, iv, ivl, n, icoord_list, dcoord_list, lvs, mhr, current_color, color_list, currently_below_threshold, leaf_label_func, level, contraction_marks, link_color_func, above_threshold_color)\u001b[0m\n\u001b[0;32m   2528\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m         _append_singleton_leaf_node(Z, p, n, level, lvs, ivl,\n\u001b[1;32m-> 2530\u001b[1;33m                                     leaf_label_func, i, labels)\n\u001b[0m\u001b[0;32m   2531\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miv\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_append_singleton_leaf_node\u001b[1;34m(Z, p, n, level, lvs, ivl, leaf_label_func, i, labels)\u001b[0m\n\u001b[0;32m   2398\u001b[0m             \u001b[1;31m# for the leaf nodes, use it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2399\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2400\u001b[1;33m                 \u001b[0mivl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2401\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2402\u001b[0m                 \u001b[1;31m# Otherwise, use the id as the label for the leaf.x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   3116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 3118\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   3119\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3120\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: -59"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3IAAARiCAYAAADhpsX0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxNPgcbDAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16058cdf7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import ward, dendrogram\n",
    "\n",
    "linkage_matrix = ward(dist) #define the linkage_matrix using ward clustering pre-computed distances\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 20)) # set size\n",
    "ax = dendrogram(linkage_matrix, orientation=\"right\", labels=X2);\n",
    "\n",
    "plt.tick_params(\\\n",
    "    axis= 'x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off')\n",
    "\n",
    "plt.tight_layout() #show plot with tight layout\n",
    "\n",
    "#uncomment below to save figure\n",
    "plt.savefig('ward_clusters.png', dpi=200) #save figure as ward_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#strip any proper names from a text...unfortunately right now this is yanking the first word from a sentence too.\n",
    "import string\n",
    "def strip_proppers(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent) if word.islower()]\n",
    "    return \"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in tokens]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#strip any proper nouns (NNP) or plural proper nouns (NNPS) from a text\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "def strip_proppers_POS(text):\n",
    "    tagged = pos_tag(text.split()) #use NLTK's part of speech tagger\n",
    "    non_propernouns = [word for word,pos in tagged if pos != 'NNP' and pos != 'NNPS']\n",
    "    return non_propernouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\124578\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.75 s\n",
      "Wall time: 359 ms\n"
     ]
    }
   ],
   "source": [
    "#Latent Dirichlet Allocation implementation with Gensim\n",
    "\n",
    "from gensim import corpora, models, similarities \n",
    "\n",
    "#remove proper names\n",
    "preprocess = [strip_proppers(doc) for doc in X3]\n",
    "\n",
    "%time tokenized_text = [tokenize_and_stem(text) for text in preprocess]\n",
    "\n",
    "%time texts = [[word for word in text if word not in stopwords] for text in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1839\n"
     ]
    }
   ],
   "source": [
    "#print(len([word for word in texts[0] if word not in stopwords]))\n",
    "print(len(texts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=1, no_above=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38.7 s\n"
     ]
    }
   ],
   "source": [
    "%time lda = models.LdaModel(corpus, num_topics=5, id2word=dictionary, update_every=5, chunksize=10000, passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.017235748), (2, 0.91388589), (4, 0.0686308)]\n"
     ]
    }
   ],
   "source": [
    "print(lda[corpus[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = lda.print_topics(5, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics_matrix = lda.show_topics(formatted=False, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: ['father', 'home', 'meet', 'kill', 'two', 'ship', 'go', 'friend', 'use', 'car', 'ask', 'love', 'come', 'call', 'away', 'want', 'explain', 'becom', 'marri', 'day']\n",
      "Topic: 1 \n",
      "Words: ['kill', 'go', 'men', 'friend', \"n't\", 'ask', 'day', 'call', 'home', 'night', 'say', 'soldier', 'goe', 'doe', 'arriv', 'two', 'run', 'fight', 'want', 'work']\n",
      "Topic: 2 \n",
      "Words: ['famili', 'polic', 'kill', 'meet', 'apart', 'car', 'ask', 'father', 'help', 'two', 'say', 'home', 'train', 'go', \"n't\", 'murder', 'friend', 'mother', 'live', 'away']\n",
      "Topic: 3 \n",
      "Words: ['first', 'film', 'run', 'night', 'train', 'town', 'live', 'arriv', 'love', 'two', 'say', 'kill', 'peopl', 'go', 'home', 'come', 'becom', 'end', 'later', 'board']\n",
      "Topic: 4 \n",
      "Words: ['kill', 'arriv', 'famili', 'ask', 'meet', 'say', 'offic', 'friend', \"n't\", 'way', 'fight', 'men', 'order', 'die', 'shoot', 'help', 'murder', 'name', 'death', 'two']\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda.show_topics(formatted=False, num_words= 20):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, [w[0] for w in topic]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(int i[0], i[1])? (<ipython-input-70-e7b1c66babbc>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-70-e7b1c66babbc>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print i[0], i[1]\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(int i[0], i[1])?\n"
     ]
    }
   ],
   "source": [
    "for i in  lda_model.show_topics():\n",
    "    print (i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, [('father', 0.004311441), ('home', 0.0042508231), ('meet', 0.0040116757), ('kill', 0.0035479241), ('two', 0.0035385143), ('ship', 0.0034096707), ('go', 0.0033582922), ('friend', 0.0033297837), ('use', 0.0033122564), ('car', 0.0032725935), ('ask', 0.0032428596), ('love', 0.0031420384), ('come', 0.0029864861), ('call', 0.002836725), ('away', 0.0027618436), ('want', 0.0027208736), ('explain', 0.0026963295), ('becom', 0.0026955884), ('marri', 0.0026336494), ('day', 0.0026115484)]), (1, [('kill', 0.0046682791), ('go', 0.0043234131), ('men', 0.0042370837), ('friend', 0.0041060313), (\"n't\", 0.004100014), ('ask', 0.0039702337), ('day', 0.0038448663), ('call', 0.0038169932), ('home', 0.0035325803), ('night', 0.0035275053), ('say', 0.0035191469), ('soldier', 0.0035141041), ('goe', 0.0033807023), ('doe', 0.0033178746), ('arriv', 0.0032430789), ('two', 0.0031804519), ('run', 0.0031299402), ('fight', 0.0031237982), ('want', 0.003110538), ('work', 0.0029915068)]), (2, [('famili', 0.0062185777), ('polic', 0.0058528385), ('kill', 0.0053333631), ('meet', 0.0049168919), ('apart', 0.0048280712), ('car', 0.0046465951), ('ask', 0.0044652391), ('father', 0.0041743293), ('help', 0.0039174054), ('two', 0.0038564522), ('say', 0.0034319358), ('home', 0.0034065938), ('train', 0.0032655329), ('go', 0.0032494501), (\"n't\", 0.0031562534), ('murder', 0.0031545146), ('friend', 0.0030773876), ('mother', 0.0030520104), ('live', 0.003009988), ('away', 0.0029234649)]), (3, [('first', 0.0043922579), ('film', 0.0040317224), ('run', 0.0039907526), ('night', 0.0039200922), ('train', 0.0033758509), ('town', 0.0032947091), ('live', 0.0031937449), ('arriv', 0.00318077), ('love', 0.0031800191), ('two', 0.0031347868), ('say', 0.0030943141), ('kill', 0.0030758057), ('peopl', 0.0030283716), ('go', 0.0030178756), ('home', 0.0029371073), ('come', 0.0029152993), ('becom', 0.0028978991), ('end', 0.0027173087), ('later', 0.002663407), ('board', 0.0024710798)]), (4, [('kill', 0.0083632525), ('arriv', 0.005433863), ('famili', 0.0041044899), ('ask', 0.0039058591), ('meet', 0.0037960981), ('say', 0.0035832042), ('offic', 0.0034818875), ('friend', 0.0033937576), (\"n't\", 0.003331728), ('way', 0.0032871352), ('fight', 0.0032676775), ('men', 0.0032074328), ('order', 0.0031966227), ('die', 0.0031834187), ('shoot', 0.0031292408), ('help', 0.0030793839), ('murder', 0.0030312126), ('name', 0.0029374301), ('death', 0.0029245508), ('two', 0.0029177382)])]\n"
     ]
    }
   ],
   "source": [
    "print(topics_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-d3382caa70f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtopics_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopics_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence"
     ]
    }
   ],
   "source": [
    "topics_matrix = np.array(topics_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-ec89312ecabd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtopics_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "topics_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-f0b9e4202156>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtopic_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopics_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "topic_words = topics_matrix[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in topic_words:\n",
    "    print([str(word) for word in i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Deep learning\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks\n",
    "from keras.initializers import VarianceScaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 563)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other methods\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Deep Learning - Autoencoders and Variational Autoencoders followed by KMeans\n",
    "https://www.analyticsvidhya.com/blog/2018/05/essentials-of-deep-learning-trudging-into-unsupervised-deep-learning/\n",
    "DEC - https://github.com/XifengGuo/DEC-keras\n",
    "\n",
    "Gaussian Mixture Model  sklearn.mixture import GaussianMixture\n",
    "SpectralClustering  sklearn.cluster import SpectralClustering\n",
    "DBSCAN -- from sklearn.cluster import DBSCAN\n",
    "MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is our input placeholder\n",
    "input_img = Input(shape=(563,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(500, activation='relu')(input_img)\n",
    "encoded = Dense(500, activation='relu')(encoded)\n",
    "encoded = Dense(2000, activation='relu')(encoded)\n",
    "encoded = Dense(10, activation='sigmoid')(encoded)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(2000, activation='relu')(encoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(563)(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 563)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 500)               282000    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2000)              1002000   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                20010     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2000)              22000     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 563)               282063    \n",
      "=================================================================\n",
      "Total params: 3,109,573\n",
      "Trainable params: 3,109,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-178b8db353e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2357\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \"\"\"\n\u001b[1;32m--> 531\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "train_history = autoencoder.fit(tfidf_matrix, tfidf_matrix, epochs=500, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_auto_train = encoder.predict(train_x)\n",
    "pred_auto = encoder.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km.fit(pred_auto_train)\n",
    "pred = km.predict(pred_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_mutual_info_score(val_y, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
